{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filters\n",
    "\n",
    "> This module implements various filters to check for specific occurrences in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import nbdev\n",
    "from stocksurfer.technicals import add_all_technicals, get_sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "base_path = nbdev.config.get_config().lib_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "processed_data_dir = base_path / \"../Data/Bhavcopy/Processed/\"\n",
    "nifty500_csv = base_path / \"../Data/Misc/ind_nifty500list.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for filtering stocks with a given strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_nifty500():\n",
    "    # Get Nifty500 list\n",
    "    return pd.read_csv(nifty500_csv).Symbol.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Load data for a symbol\n",
    "def get_symbol_data(symbol):\n",
    "    file_path = base_path / processed_data_dir / f\"{symbol}.parquet\"\n",
    "\n",
    "    if not file_path.exists():\n",
    "        return None\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df[\"DATE\"] = pd.to_datetime(df['DATE'])#apply(lambda x: x.strftime('%Y-%d-%m'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Convert daily data to monthly data\n",
    "def get_monthly_data(df):\n",
    "    return df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first', 'DATE': 'first'}).reset_index(drop=True)\n",
    "\n",
    "# Convert daily data to weekly data\n",
    "def get_weekly_data(df):\n",
    "    return df.resample('W', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first', 'DATE': 'first'}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check if the latest candle spans the given SMAs\n",
    "def single_candle_span(df, kwargs=None):\n",
    "    if kwargs and 'col_list' in kwargs.keys():\n",
    "        col_list = kwargs['col_list']\n",
    "    else:\n",
    "        col_list = [\"SMA_20_C\", \"SMA_200_C\"]\n",
    "    \n",
    "    conditions = [\n",
    "        df.LOW.iloc[-1] <= df[col].iloc[-1] <= df.HIGH.iloc[-1]\n",
    "        for col in col_list\n",
    "    ]\n",
    "    if all(conditions):\n",
    "        print(\n",
    "            f\"{df.SYMBOL.iloc[0]} -> Single candle span on {df.DATE.iloc[-1]}\"\n",
    "        )\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check if the latest candle is a hammer\n",
    "def hammer_on_BBL(df, kwargs=None):\n",
    "    \n",
    "    body = df.iloc[-1].CLOSE - df.iloc[-1].OPEN\n",
    "    upper_wick = df.iloc[-1].HIGH - df.iloc[-1].CLOSE\n",
    "    lower_wick = df.iloc[-1].OPEN - df.iloc[-1].LOW\n",
    "    \n",
    "    conditions = [\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        lower_wick >= 2*body,\n",
    "        body >= 1.5*upper_wick,\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].BBL_20_2 > df.iloc[-1].LOW,\n",
    "    ]\n",
    "    \n",
    "    if all(conditions):\n",
    "        print(f\"{df.SYMBOL.iloc[0]} -> Hammer on BBL on {df.DATE.iloc[-1]}\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check if latest candle is green takes out red on BBL\n",
    "def green_engulfing_on_BBL(df, kwargs=None):\n",
    "    conditions = [\n",
    "        df.iloc[-2].CLOSE < df.iloc[-2].OPEN,\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        df.iloc[-1].LOW < df.iloc[-1].BBL_20_2 < df.iloc[-1].HIGH,\n",
    "        df.iloc[-1].CLOSE > df.iloc[-2].OPEN,\n",
    "    ]\n",
    "    \n",
    "    if all(conditions):\n",
    "        print(f\"{df.SYMBOL.iloc[0]} -> Green engulfing on BBL on {df.DATE.iloc[-1]}\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check for three rising green candles\n",
    "def three_rising_green_candles_on_SMA20(df, kwargs=None):\n",
    "    conditions = [\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        df.iloc[-2].CLOSE > df.iloc[-2].OPEN,\n",
    "        df.iloc[-3].CLOSE > df.iloc[-3].OPEN,\n",
    "    \n",
    "        df.iloc[-1].CLOSE > df.iloc[-2].CLOSE,\n",
    "        df.iloc[-2].CLOSE > df.iloc[-3].CLOSE,\n",
    "        \n",
    "        df.iloc[-3].CLOSE > df.iloc[-3].SMA_20_C,\n",
    "        df.iloc[-3].LOW < df.iloc[-3].SMA_20_C,\n",
    "    ]\n",
    "    \n",
    "    if all(conditions):\n",
    "        print(f\"{df.SYMBOL.iloc[0]} -> Three rising green candles on {df.DATE.iloc[-1]}\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check for SMA 20 catch\n",
    "def sma20_catch(df, kwargs=None):\n",
    "    conditions = [\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        df.iloc[-2].CLOSE > df.iloc[-2].OPEN,\n",
    "        \n",
    "        df.iloc[-2].LOW < df.iloc[-2].SMA_20_C,\n",
    "        df.iloc[-1].LOW > df.iloc[-1].SMA_20_C,\n",
    "    ]\n",
    "    \n",
    "    if all(conditions):\n",
    "        print(f\"{df.SYMBOL.iloc[0]} -> SMA 20 catch on {df.DATE.iloc[-1]}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def filter_stocks(symbols=None, timeframe = \"daily\", cutoff_date = None, strategy=None, strategy_args=None, ):\n",
    "    \n",
    "    if not symbols:\n",
    "        symbols = get_nifty500()\n",
    "    elif symbols == \"all\":\n",
    "        symbols = [f.stem for f in processed_data_dir.glob(\"*.parquet\")] \n",
    "    for symbol in symbols:\n",
    "        df = get_symbol_data(symbol)\n",
    "        if df is None:\n",
    "            print(f\"Data not found for {symbol}\")\n",
    "        else:\n",
    "            if cutoff_date:\n",
    "                df = df.query(\"DATE < @cutoff_date\")\n",
    "            if timeframe.lower() == \"monthly\":\n",
    "                df = add_all_technicals(get_monthly_data(df))\n",
    "            elif timeframe.lower() == \"weekly\":\n",
    "                df = add_all_technicals(get_weekly_data(df))\n",
    "\n",
    "            # Pass strategy args to the strategy method and run it\n",
    "            strategy(df, kwargs=strategy_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLLTD -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "AMARAJABAT -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "BAJAJHLDNG -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "BANKBARODA -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "MAHABANK -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "BERGEPAINT -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "BPCL -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "BBTC -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "CENTURYPLY -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "CHEMPLASTS -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "CUMMINSIND -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "DELHIVERY -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "FDC -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "HAVELLS -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "HINDPETRO -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "IDFC -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "INDIANB -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "INDIGO -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "JSL -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "MAZDOCK -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "METROBRAND -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "NATIONALUM -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "Data not found for PATANJALI\n",
      "POLYMED -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "RITES -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "RAYMOND -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "SBICARD -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "SUPREMEIND -> SMA 20 catch on 2023-04-24 00:00:00\n",
      "Data not found for UNOMINDA\n",
      "ZOMATO -> SMA 20 catch on 2023-04-24 00:00:00\n"
     ]
    }
   ],
   "source": [
    "filter_stocks(\n",
    "    timeframe=\"weekly\",\n",
    "    # cutoff_date=datetime(2023,4, 27),\n",
    "    strategy=sma20_catch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOLLOTYRE -> Three rising green candles on 2023-04-24 00:00:00\n",
      "BANKBARODA -> Three rising green candles on 2023-04-24 00:00:00\n",
      "DIVISLAB -> Three rising green candles on 2023-04-24 00:00:00\n",
      "EXIDEIND -> Three rising green candles on 2023-04-24 00:00:00\n",
      "FDC -> Three rising green candles on 2023-04-24 00:00:00\n",
      "HEG -> Three rising green candles on 2023-04-24 00:00:00\n",
      "KOTAKBANK -> Three rising green candles on 2023-04-24 00:00:00\n",
      "KIMS -> Three rising green candles on 2023-04-24 00:00:00\n",
      "MTARTECH -> Three rising green candles on 2023-04-24 00:00:00\n",
      "Data not found for PATANJALI\n",
      "PRESTIGE -> Three rising green candles on 2023-04-24 00:00:00\n",
      "SONACOMS -> Three rising green candles on 2023-04-24 00:00:00\n",
      "SUPREMEIND -> Three rising green candles on 2023-04-24 00:00:00\n",
      "Data not found for UNOMINDA\n"
     ]
    }
   ],
   "source": [
    "filter_stocks(\n",
    "    timeframe=\"weekly\",\n",
    "    # cutoff_date=datetime(2023,4, 27),\n",
    "    strategy=three_rising_green_candles_on_SMA20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data not found for PATANJALI\n",
      "Data not found for UNOMINDA\n"
     ]
    }
   ],
   "source": [
    "filter_stocks(\n",
    "    timeframe=\"weekly\",\n",
    "    # cutoff_date=datetime(2023,4, 27),\n",
    "    strategy=hammer_on_BBL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESABINDIA -> Green engulfing on BBL on 2023-04-24 00:00:00\n",
      "HCG -> Green engulfing on BBL on 2023-04-24 00:00:00\n",
      "ITBEES -> Green engulfing on BBL on 2023-04-24 00:00:00\n",
      "STARTECK -> Green engulfing on BBL on 2023-04-24 00:00:00\n"
     ]
    }
   ],
   "source": [
    "filter_stocks(\n",
    "    symbols=\"all\",\n",
    "    timeframe=\"weekly\",\n",
    "    # cutoff_date=datetime(2023,3, 31),\n",
    "    strategy=green_engulfing_on_BBL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3MINDIA -> Single candle span on 2023-04-24 00:00:00\n",
      "ENDURANCE -> Single candle span on 2023-04-24 00:00:00\n",
      "IFBIND -> Single candle span on 2023-04-24 00:00:00\n",
      "INTELLECT -> Single candle span on 2023-04-24 00:00:00\n",
      "MMTC -> Single candle span on 2023-04-24 00:00:00\n",
      "MOIL -> Single candle span on 2023-04-24 00:00:00\n",
      "MAHLIFE -> Single candle span on 2023-04-24 00:00:00\n",
      "MCX -> Single candle span on 2023-04-24 00:00:00\n",
      "Data not found for PATANJALI\n",
      "Data not found for UNOMINDA\n"
     ]
    }
   ],
   "source": [
    "filter_stocks(\n",
    "    timeframe=\"weekly\",\n",
    "    cutoff_date=datetime(2023,5, 3),\n",
    "    strategy=single_candle_span,\n",
    "    # strategy_args={\"col_list\": [\"SMA_20_C\", \"SMA_200_C\", \"SMA_44_C\"]},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 SMA HALT STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_directional_crossover(df, col1, col2, days_lookback=7):\n",
    "    days_lookback = min(days_lookback + 1, df.shape[0])\n",
    "    for d in range(1, days_lookback):\n",
    "        # print(f\"Checking for {df.DATE.iloc[-d]}: {df[col1].iloc[-d]}, {df[col2].iloc[-d]}\")\n",
    "        if (\n",
    "            df[col1].iloc[-d] > df[col2].iloc[-d]\n",
    "            and df[col1].iloc[-d - 1] < df[col2].iloc[-d - 1]\n",
    "        ):\n",
    "            # print(f\"{col1} crossed over {col2} on {df.DATE.iloc[-d]} : {d} days ago\")\n",
    "            return d\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_close_under_falling_20(df, d, days_lookback=10):\n",
    "    df = df.iloc[-d - days_lookback : -d]\n",
    "    # print(df.DATE.iloc[0], df.DATE.iloc[-1])\n",
    "    # df.plot(x=\"DATE\", y=[\"CLOSE\", \"SMA_20_C\"], figsize=(15, 5))\n",
    "    # df.plot(x=\"DATE\", y=[\"CLOSE\", \"SMA_20_C\", \"SMA_20_H\"], figsize=(15, 5))\n",
    "    # print(df.SMA_20_C.is_monotonic_decreasing, df.SMA_20_H.is_monotonic_decreasing)\n",
    "    return all(\n",
    "        [\n",
    "            any(\n",
    "                [\n",
    "                    df.SMA_20_C.is_monotonic_decreasing,\n",
    "                    df.SMA_20_H.is_monotonic_decreasing,\n",
    "                    df.SMA_44_C.is_monotonic_decreasing,\n",
    "                ]\n",
    "            ),\n",
    "            any(\n",
    "                [\n",
    "                    all(df.CLOSE < df.SMA_20_H),\n",
    "                    # all(df.CLOSE < df.SMA_20_C)\n",
    "                ]\n",
    "            ),\n",
    "            # all(df.SMA_200_C < df.SMA_20_C)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# check_close_under_20(df, 15, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_close_above_20(df, d, days_lookfwd=3):\n",
    "    df = df.iloc[-d + 1 :].head(days_lookfwd)\n",
    "    # print(df)\n",
    "    # print(df.DATE.iloc[0], df.DATE.iloc[-1])\n",
    "    # df.plot(x=\"DATE\", y=[\"CLOSE\", \"SMA_20_C\"], figsize=(15, 5))\n",
    "    return all(df.CLOSE > df.SMA_20_C)  # df.SMA_20_C.is_monotonic_increasing and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_20_200_breakout(df, days_lookback=5):\n",
    "    found = False\n",
    "    col1 = \"CLOSE\"\n",
    "    col2 = \"SMA_20_C\"\n",
    "    col3 = \"SMA_200_C\"\n",
    "    col4 = \"SMA_20_H\"\n",
    "    # df = df[:-45]\n",
    "\n",
    "    # Check for double crossover on SMA20 and SMA200 within a 3 day period\n",
    "    dc20 = check_directional_crossover(df, col1, col2, days_lookback=days_lookback)\n",
    "    if all(\n",
    "        [\n",
    "            dc20 > 0,\n",
    "            check_close_under_falling_20(df, dc20, days_lookback=30),\n",
    "            check_close_above_20(df, dc20),\n",
    "        ]\n",
    "    ):\n",
    "        found = True\n",
    "        dc200 = check_directional_crossover(df, col1, col3, days_lookback=days_lookback)\n",
    "        # print(dc20, dc200)\n",
    "\n",
    "        if all([dc200 > 0, abs(dc20 - dc200) < 3]):\n",
    "            print(\n",
    "                f\"{df.SYMBOL.iloc[0]} -> Double crossover on {df.DATE.iloc[-dc20]} : {dc20} days ago, with {df.iloc[-dc20].CDL_COLOR} candle\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"{df.SYMBOL.iloc[0]} -> SMA20 crossover on {df.DATE.iloc[-dc20]} : {dc20} days ago, with {df.iloc[-dc20].CDL_COLOR} candle\"\n",
    "            )\n",
    "            if dc200:\n",
    "                print(\n",
    "                    f\"{df.SYMBOL.iloc[0]} -> SMA 200 crossover: {df.DATE.iloc[-dc200]} : {dc200} days ago, with {df.iloc[-dc200].CDL_COLOR} candle\"\n",
    "                )\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_3_green_on_sma20(df):\n",
    "    crossover = check_directional_crossover(df, \"CLOSE\", \"SMA_20_C\", days_lookback=15)\n",
    "    if all([\n",
    "        crossover > 2,\n",
    "        df.iloc[-crossover].CDL_COLOR == \"green\",\n",
    "        df.iloc[-crossover+1].CDL_COLOR == \"green\",\n",
    "        df.iloc[-crossover+2].CDL_COLOR == \"green\",\n",
    "        df.iloc[-crossover+1].CLOSE > df.iloc[-crossover].CLOSE,\n",
    "        df.iloc[-crossover+2].CLOSE > df.iloc[-crossover+1].CLOSE,\n",
    "        df.iloc[-crossover+2].CLOSE < df.iloc[-crossover+2].BBU_20_2,\n",
    "        # df.iloc[-crossover].BBB_20_2 > 8,\n",
    "        df.iloc[-crossover+1].SMA_20_C > df.iloc[-crossover-1].SMA_20_C\n",
    "        # crossover > 10,\n",
    "    ]):\n",
    "        max_close = max(df[-crossover+1:].CLOSE)\n",
    "        perc_movement = 100* (max_close - df.iloc[-crossover+2].CLOSE) / df.iloc[-crossover+2].CLOSE\n",
    "        print(f\"{df.SYMBOL.iloc[0]} -> SMA20 crossover on {df.DATE.iloc[-crossover]} : BBB = {df.BBB_20_2.iloc[-crossover]:0.2f} : Moved {perc_movement:.2f}%, upto {max_close}\")\n",
    "    # else:\n",
    "    #     print(crossover)\n",
    "\n",
    "# df[-crossover-5:-crossover + 5][[\"DATE\", \"CLOSE\", \"SMA_20_C\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in df500:\n",
    "#     df = get_symbol_data(symbol)\n",
    "#     if df is not None:\n",
    "#         check_3_green_on_sma20(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_symbol_data(\"PNB\")\n",
    "# window = 500\n",
    "# df.tail(window).plot(\n",
    "#     x=\"DATE\",\n",
    "#     y=[\n",
    "#         # \"BBU_20_2\",\n",
    "#         # \"BBM_20_2\",\n",
    "#         # \"BBL_20_2\",\n",
    "#         \"BBB_20_2\",\n",
    "#         # \"BBP_20_2\",\n",
    "#         \"CLOSE\"\n",
    "#     ],\n",
    "#     figsize=(18, 15),\n",
    "# )\n",
    "# df.tail(window).plot(\n",
    "#     x=\"DATE\",\n",
    "#     y=[\n",
    "#         \"CLOSE\"\n",
    "#     ],\n",
    "#     figsize=(18, 5),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMA 20 & SMA 200 Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find stocks with SMA20 and SMA44 single candle span\n",
    "# for symbol in df500:\n",
    "#     df = get_symbol_data(symbol)\n",
    "#     if df is not None:\n",
    "#         check_single_candle_span(\n",
    "#             df, col_list=[\"SMA_20_C\", \"SMA_44_C\", \"SMA_200_C\"], days_lookback=2\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find stocks with 20ma crossover preceded by time under a falling SMA20\n",
    "# for symbol in df500:\n",
    "#     df = get_symbol_data(symbol)\n",
    "#     if df is not None:\n",
    "#         a = check_20_200_breakout(df)\n",
    "#         if a:\n",
    "#             b = check_single_candle_span(\n",
    "#                 df, col_list=[\"SMA_20_C\", \"SMA_44_C\", \"SMA_200_C\"], days_lookback=5\n",
    "#             )\n",
    "#             print(\"-\" * 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALLTIME HIGH STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_historical_minmax(df, min_steps_back=30, mode=None):\n",
    "    if mode is None or mode == \"all\":\n",
    "        mode = [\"min\", \"max\"]\n",
    "\n",
    "    if \"DATE\" not in df.columns:\n",
    "        df[\"DATE\"] = df.index\n",
    "\n",
    "    max_steps = len(df)\n",
    "    if max_steps > min_steps_back:\n",
    "        if \"max\" in mode or mode == \"max\":\n",
    "            # Search for historical high\n",
    "            last_is_max = True\n",
    "            steps_back = 1\n",
    "            while last_is_max:\n",
    "                steps_back += 1\n",
    "                if steps_back > max_steps:\n",
    "                    print(\n",
    "                        f\"{df.SYMBOL.iloc[-1]}: ALL TIME HIGH on {df.DATE.iloc[-1].date()} closed at {df.CLOSE.iloc[-1]}\"\n",
    "                    )\n",
    "                    return\n",
    "                last_is_max = df.CLOSE.iloc[-1] >= df.HIGH.iloc[-steps_back]\n",
    "\n",
    "            if steps_back >= min_steps_back:\n",
    "                print(\n",
    "                    f\"{df.SYMBOL.iloc[-1]} CLOSE -> {df.CLOSE.iloc[-1]} : New high of {steps_back} sessions, since HIGH of {df.HIGH.iloc[-steps_back]} on {df.DATE.iloc[-steps_back].date()}\"\n",
    "                )\n",
    "\n",
    "        if \"min\" in mode or mode == \"min\":\n",
    "            # Search for historical low\n",
    "            last_is_min = True\n",
    "            steps_back = 1\n",
    "            while last_is_min:\n",
    "                steps_back += 1\n",
    "                if steps_back > max_steps:\n",
    "                    print(\n",
    "                        f\"{df.SYMBOL.iloc[-1]}: ALL TIME LOW on {df.DATE.iloc[-1].date()} closed at {df.CLOSE.iloc[-1]}\"\n",
    "                    )\n",
    "                    return\n",
    "                last_is_min = df.CLOSE.iloc[-1] <= df.LOW.iloc[-steps_back]\n",
    "\n",
    "            if steps_back >= min_steps_back:\n",
    "                print(\n",
    "                    f\"{df.SYMBOL.iloc[-1]} CLOSE -> {df.CLOSE.iloc[-1]} : New low of {steps_back} sessions, since LOW of {df.LOW.iloc[-steps_back]} on {df.DATE.iloc[-steps_back].date()}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist: c:\\MyData\\TechWork\\stocksurfer\\stocksurfer\\..\\Data\\Bhavcopy\\Processed\\BAJAJFINSV.csv\n"
     ]
    }
   ],
   "source": [
    "symbol = \"BAJAJFINSV\"\n",
    "file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "if not file_path.exists():\n",
    "    print(f\"File does not exist: {file_path}\")\n",
    "else:\n",
    "    print(f\"File exists: {file_path}\")\n",
    "    df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "    # Convert daily data to monthly data\n",
    "    df_monthly = df.resample(\"M\", on=\"DATE\").agg(\n",
    "        {\n",
    "            \"OPEN\": \"first\",\n",
    "            \"HIGH\": \"max\",\n",
    "            \"LOW\": \"min\",\n",
    "            \"CLOSE\": \"last\",\n",
    "            \"SYMBOL\": \"first\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    check_historical_minmax(df, min_steps_back=4, mode=None)\n",
    "    # check_historical_minmax(df_monthly, min_steps_back=4, mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in df500:\n",
    "#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "#     if file_path.exists():\n",
    "#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "#         # Convert daily data to monthly data\n",
    "#         df_monthly = df.resample(\"M\", on=\"DATE\").agg(\n",
    "#             {\n",
    "#                 \"OPEN\": \"first\",\n",
    "#                 \"HIGH\": \"max\",\n",
    "#                 \"LOW\": \"min\",\n",
    "#                 \"CLOSE\": \"last\",\n",
    "#                 \"SYMBOL\": \"first\",\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         # check_historical_minmax(df, min_steps_back=30, mode=\"max\")\n",
    "#         check_historical_minmax(df_monthly, min_steps_back=36, mode=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all csv files in raw_data_dir\n",
    "# csv_files = [f for f in raw_data_dir.iterdir() if f.suffix == '.csv']\n",
    "\n",
    "# for file in csv_files:\n",
    "#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "#     if os.path.exists(file_path):\n",
    "#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "\n",
    "#         # Convert daily data to monthly data\n",
    "#         df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n",
    "\n",
    "#         # check_historical_minmax(df, min_steps_back=300, mode=\"max\")\n",
    "#         check_historical_minmax(df_monthly, min_steps_back=60, mode=\"max\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movement in a band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_movement_within_band(df, band_perc=5, steps_lookback=20):\n",
    "    steps_lookback = min(steps_lookback + 1, df.shape[0])\n",
    "    max_steps = len(df)\n",
    "\n",
    "    band_max = df.CLOSE.iloc[-1] * (1 + band_perc / 100)\n",
    "    band_min = df.CLOSE.iloc[-1] * (1 - band_perc / 100)\n",
    "\n",
    "    in_band = True\n",
    "    steps_back = 1\n",
    "    while in_band:\n",
    "        steps_back += 1\n",
    "        if steps_back > max_steps:\n",
    "            print(\n",
    "                f\"{df.SYMBOL.iloc[-1]}: Within band of {band_perc}% for {steps_back-1} sessions for band: {band_min:0.2f} to {band_max:0.2f}\"\n",
    "            )\n",
    "            return\n",
    "        in_band = (df.CLOSE.iloc[-steps_back] <= band_max) and (\n",
    "            df.CLOSE.iloc[-steps_back] >= band_min\n",
    "        )\n",
    "\n",
    "    if steps_back >= steps_lookback:\n",
    "        print(\n",
    "            f\"{df.SYMBOL.iloc[-1]} CLOSE -> {df.CLOSE.iloc[-1]} : Within band of {band_perc}% for {steps_back-1} sessions for band: {band_min:0.2f} to {band_max:0.2f}\"\n",
    "        )\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol = \"VAIBHAVGBL\"\n",
    "# file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "# if not os.path.exists(file_path):\n",
    "#     print(f\"File does not exist: {file_path}\")\n",
    "# else:\n",
    "#     print(f\"File exists: {file_path}\")\n",
    "#     df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "#     df = df.query(\"DATE < '2022-08-27'\")\n",
    "#     check_movement_within_band(df, band_perc=5, steps_lookback=20)\n",
    "\n",
    "# Convert daily data to monthly data\n",
    "# df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in df500:\n",
    "#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "#     if os.path.exists(file_path):\n",
    "#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "\n",
    "#         check_movement_within_band(df, band_perc=3, steps_lookback=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_3_green_on_SMA(df, sma_period=20):\n",
    "\n",
    "#     if df.shape[0] < sma_period:\n",
    "#         return\n",
    "\n",
    "#     if all([\n",
    "#         df.OPEN.iloc[-3] < df.SMA_20_C.iloc[-3] < df.CLOSE.iloc[-3],\n",
    "#         df.OPEN.iloc[-2] < df.CLOSE.iloc[-2],\n",
    "#         df.OPEN.iloc[-1] < df.CLOSE.iloc[-1],\n",
    "#         df.CLOSE.iloc[-1] > df.CLOSE.iloc[-2] > df.CLOSE.iloc[-3],\n",
    "#     ]): # 3 green candles on SMA\n",
    "\n",
    "#         print(f\"{df.SYMBOL.iloc[-1]}: 3 green candles on SMA 20 on {df.DATE.iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all csv files in raw_data_dir\n",
    "# csv_files = [f for f in os.listdir(processed_data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# for file in csv_files:\n",
    "#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "#     if os.path.exists(file_path):\n",
    "#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "\n",
    "#         # Convert daily data to monthly data\n",
    "#         # df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n",
    "\n",
    "#         # Convert daily data to weekly data\n",
    "#         df_weekly = df.resample('W', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n",
    "#         df_weekly['SMA_20_C'] = df_weekly.CLOSE.rolling(20).mean()\n",
    "#         if \"DATE\" not in df_weekly.columns:\n",
    "#             df_weekly[\"DATE\"] = df_weekly.index\n",
    "\n",
    "#         check_3_green_on_SMA(df_weekly, sma_period=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download csv from URL\n",
    "# url = r\"https://www.nseindia.com/api/equity-stockIndices?csv=true&index=SECURITIES%20IN%20F%26O\"\n",
    "# df = pd.read_csv(url)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# # Download csv from URL using requests\n",
    "# url = r\"https://www.nseindia.com/api/equity-stockIndices?csv=true&index=SECURITIES%20IN%20F%26O\"\n",
    "# requests.get(url).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nseindia.com/market-data/live-equity-market\n",
    "\n",
    "# https://www.nseindia.com/api/equity-stockIndices?csv=true&index=NIFTY%20SMALLCAP%2050\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_cap = 200000\n",
    "# win_rate = 0.6\n",
    "# one_trade_perc = 0.02\n",
    "\n",
    "# for i in range(200):\n",
    "#     if random.random() < win_rate:\n",
    "#         init_cap = init_cap * (1 + one_trade_perc)\n",
    "#     else:\n",
    "#         init_cap = init_cap * (1 - one_trade_perc)\n",
    "\n",
    "# print(f'{init_cap:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
