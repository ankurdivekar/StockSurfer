{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filters\n",
    "\n",
    "> This module implements various filters to check for specific occurrences in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import nbdev\n",
    "from stocksurfer.technicals import (\n",
    "    get_symbol_data,\n",
    "    add_all_technicals,\n",
    "    get_monthly_data,\n",
    "    get_weekly_data,\n",
    "    get_bollinger_bands,\n",
    "    get_keltner_channels,\n",
    ")\n",
    "from stocksurfer.scrapers import (\n",
    "    get_nifty500_stocks,\n",
    "    get_nifty100_stocks,\n",
    "    get_fno_stocks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "base_path = nbdev.config.get_config().lib_path\n",
    "processed_data_dir = base_path / \"../Data/Bhavcopy/Processed\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for filtering stocks with a given strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def filter_stocks(\n",
    "    symbols=None,\n",
    "    timeframe=\"daily\",\n",
    "    cutoff_date=None,\n",
    "    lookback=0,\n",
    "    n_detections=0,\n",
    "    strategy=None,\n",
    "    strategy_args=None,\n",
    "):\n",
    "    match symbols:\n",
    "        case None:\n",
    "            symbols = get_nifty500_stocks()\n",
    "        case \"nifty100\":\n",
    "            symbols = get_nifty100_stocks()\n",
    "        case \"nifty500\":\n",
    "            symbols = get_nifty500_stocks()\n",
    "        case \"fno\":\n",
    "            symbols = get_fno_stocks()\n",
    "        case \"all\":\n",
    "            symbols = [f.stem for f in processed_data_dir.glob(\"*.parquet\")]\n",
    "\n",
    "    # if not symbols:\n",
    "    #     symbols = get_nifty500_stocks()\n",
    "    # elif symbols == \"nifty100\":\n",
    "    #     symbols = get_nifty100_stocks()\n",
    "    # elif symbols == \"fno\":\n",
    "    #     symbols = get_fno_stocks()\n",
    "    # elif symbols == \"all\":\n",
    "    #     symbols = [f.stem for f in processed_data_dir.glob(\"*.parquet\")]\n",
    "\n",
    "    for symbol in symbols:\n",
    "        # print(symbol)\n",
    "        df = get_symbol_data(symbol)\n",
    "        if df is None:\n",
    "            print(f\"Data not found for {symbol}\")\n",
    "        elif len(df) < 202:\n",
    "            # print(f\"Data not sufficient for {symbol}: {len(df)} rows\")\n",
    "            pass\n",
    "        else:\n",
    "            # Filter data by cutoff data\n",
    "            if cutoff_date:\n",
    "                df = df.query(\"DATE < @cutoff_date\")\n",
    "\n",
    "            # Resample data to monthly or weekly\n",
    "            if timeframe.lower() == \"monthly\":\n",
    "                df = add_all_technicals(get_monthly_data(df))\n",
    "            elif timeframe.lower() == \"weekly\":\n",
    "                df = add_all_technicals(get_weekly_data(df))\n",
    "\n",
    "            # Iteratively evaluate strategy for lookback period\n",
    "            detection_count = 0\n",
    "            for lb in range(min(lookback + 1, len(df) - 1)):\n",
    "                df_lb = df.drop(df.tail(lb).index)\n",
    "\n",
    "                # Pass strategy args to the strategy method and run it\n",
    "                if strategy(df_lb, kwargs=strategy_args):\n",
    "                    print(\n",
    "                        f\"{symbol:>15} -> {strategy.__name__} on {df_lb.DATE.iloc[-1].date()} @ {df_lb.CLOSE.iloc[-1]}\"\n",
    "                    )\n",
    "                    detection_count += 1\n",
    "                    if detection_count == n_detections:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = add_all_technicals(get_weekly_data(get_symbol_data(\"UPL\")))\n",
    "#  # Get df tail\n",
    "# df_tail = df.tail(15)\n",
    "\n",
    "# # Get 200-20 diff\n",
    "# tail_diff = df_tail.apply(lambda x: x.SMA_200_C - x.SMA_20_C, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tail.plot(x=\"DATE\", y=[\"SMA_200_C\", \"SMA_20_C\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_symbol_data(\"TCNSBRANDS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bollinger squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def bollinger_squeeze(df, kwargs=None):\n",
    "    # Get args\n",
    "    window = kwargs[\"window\"] if kwargs and \"window\" in kwargs.keys() else 10\n",
    "    threshold = kwargs[\"threshold\"] if kwargs and \"threshold\" in kwargs.keys() else 3\n",
    "\n",
    "    if \"BB_U\" not in df.columns:\n",
    "        df = get_bollinger_bands(df)\n",
    "\n",
    "    conditions = [\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        df.iloc[-1].BB_B > threshold,\n",
    "        all(df.iloc[-window - 1 : -1].BB_B < threshold),\n",
    "    ]\n",
    "\n",
    "    return all(conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bollinger-Keltner breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def bollinger_keltner_breakout(df, kwargs=None):\n",
    "    # Get args\n",
    "    window = kwargs[\"window\"] if kwargs and \"window\" in kwargs.keys() else 10\n",
    "\n",
    "    if \"KC_U\" not in df.columns:\n",
    "        df = get_keltner_channels(df)\n",
    "    if \"BB_U\" not in df.columns:\n",
    "        df = get_bollinger_bands(df)\n",
    "\n",
    "    conditions = [\n",
    "        all(df.iloc[-window - 1 : -1].KC_U > df.iloc[-window - 1 : -1].BB_U),\n",
    "        all(df.iloc[-window - 1 : -1].KC_L < df.iloc[-window - 1 : -1].BB_L),\n",
    "        any(\n",
    "            [\n",
    "                df.iloc[-1].KC_U < df.iloc[-1].BB_U,\n",
    "                df.iloc[-1].KC_L > df.iloc[-1].BB_L,\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return all(conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume surge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def volume_surge(df, kwargs=None):\n",
    "    # Get args\n",
    "    window = kwargs[\"window\"] if kwargs and \"window\" in kwargs.keys() else 12\n",
    "    surge_factor = (\n",
    "        kwargs[\"surge_factor\"] if kwargs and \"surge_factor\" in kwargs.keys() else 3\n",
    "    )\n",
    "\n",
    "    # vol_mean = df.iloc[-window-1:-1].TOTTRDQTY.mean()\n",
    "    vol_max = df.iloc[-window - 1 : -1].TOTTRDQTY.max()\n",
    "\n",
    "    conditions = [\n",
    "        vol_max * surge_factor < df.iloc[-1].TOTTRDQTY,\n",
    "        # df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "    ]\n",
    "\n",
    "    return all(conditions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200-20 wedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check for a 200-20 wedge position\n",
    "def wedge_200_20(df, kwargs=None):\n",
    "    # Get args\n",
    "    window = kwargs[\"window\"] if kwargs and \"window\" in kwargs.keys() else 12\n",
    "\n",
    "    # Get df tail\n",
    "    df_tail = df.tail(window)\n",
    "\n",
    "    # Get 200-20 diff\n",
    "    tail_diff = df_tail.apply(lambda x: x.SMA_200_C - x.SMA_20_C, axis=1)\n",
    "\n",
    "    conditions = [\n",
    "        # SMA 20 is rising\n",
    "        df_tail.SMA_20_C.is_monotonic_increasing,\n",
    "        # SMA 20 is roughly rising, calculated as 75% of candles are closing higher than previous candle\n",
    "        # ((df_tail.SMA_20_C.diff() > 0).sum()+1)/(len(df_tail)) > 0.75,\n",
    "        # SMA 200 and SMA 20 are converging\n",
    "        tail_diff.is_monotonic_decreasing,\n",
    "        # SMA 200 is above SMA 20\n",
    "        all(tail_diff > 0),\n",
    "        # SMA 200 and SMA 20 are within x% of each other\n",
    "        all(tail_diff < df_tail.SMA_200_C * 0.2),\n",
    "        # Any of these positions\n",
    "        any(\n",
    "            [\n",
    "                # Last candle has crossed SMA 200 with green candle\n",
    "                df.iloc[-1].CLOSE > df.iloc[-1].SMA_200_C > df.iloc[-1].LOW,\n",
    "                # Last candle is cleanly above SMA 200 and the one before spanned SMA 200 but closed below it\n",
    "                df.iloc[-1].LOW > df.iloc[-1].SMA_200_C\n",
    "                and df.iloc[-2].HIGH > df.iloc[-2].SMA_200_C > df.iloc[-2].LOW,\n",
    "                # Last candle is cleanly above SMA 200 and the one before is cleanly below SMA 200\n",
    "                df.iloc[-1].LOW > df.iloc[-1].SMA_200_C\n",
    "                and df.iloc[-2].HIGH < df.iloc[-2].SMA_200_C,\n",
    "            ]\n",
    "        ),\n",
    "        # Candle before last has closed below SMA 200\n",
    "        # df.iloc[-2].CLOSE < df.iloc[-2].SMA_200_C,\n",
    "        # Body of last candle should be bigger than upper and lower wick\n",
    "        df.iloc[-1].CLOSE - df.iloc[-1].OPEN > df.iloc[-1].HIGH - df.iloc[-1].CLOSE,\n",
    "        df.iloc[-1].CLOSE - df.iloc[-1].OPEN > df.iloc[-1].OPEN - df.iloc[-1].LOW,\n",
    "        # SMA 20 crosses over SMA 200 from below\n",
    "        # df.iloc[-1].SMA_20_C > df.iloc[-1].SMA_200_C,\n",
    "        # df.iloc[-2].SMA_20_C < df.iloc[-2].SMA_200_C,\n",
    "        # df.iloc[-2].CLOSE < df.iloc[-2].SMA_200_C,\n",
    "        # df.iloc[-3].CLOSE < df.iloc[-3].SMA_200_C,\n",
    "    ]\n",
    "\n",
    "    return all(conditions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMA catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check for SMA 20 catch\n",
    "def level_catch(df, kwargs=None):\n",
    "    # Get args\n",
    "    level = kwargs[\"level\"] if kwargs and \"level\" in kwargs.keys() else \"SMA_200_C\"\n",
    "\n",
    "    conditions = [\n",
    "        # df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        df.iloc[-2].CLOSE > df.iloc[-2].OPEN,\n",
    "        df.iloc[-2].LOW < df.iloc[-2][level],\n",
    "        min(df.iloc[-1].OPEN, df.iloc[-1].CLOSE) > df.iloc[-1][level],\n",
    "        df.iloc[-1].CLOSE > df.iloc[-2].CLOSE,\n",
    "    ]\n",
    "\n",
    "    return all(conditions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alltime high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check for alltime high\n",
    "def alltime_high(df, kwargs=None):\n",
    "    df2 = df[:-1]\n",
    "    conditions = [\n",
    "        df.iloc[-1].CLOSE >= df2.HIGH.max(),\n",
    "        df.iloc[-2].CLOSE < df2.HIGH.max(),\n",
    "        df.iloc[-3].CLOSE < df2.HIGH.max(),\n",
    "        df.iloc[-4].CLOSE < df2.HIGH.max(),\n",
    "        df.iloc[-5].CLOSE < df2.HIGH.max(),\n",
    "    ]\n",
    "\n",
    "    return all(conditions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single candle span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check if the latest candle spans the given SMAs\n",
    "def single_candle_span(df, kwargs=None):\n",
    "    col_list = (\n",
    "        kwargs[\"col_list\"]\n",
    "        if kwargs and \"col_list\" in kwargs.keys()\n",
    "        else [\"SMA_20_C\", \"SMA_200_C\"]\n",
    "    )\n",
    "\n",
    "    conditions = [\n",
    "        df.LOW.iloc[-1] <= df[col].iloc[-1] <= df.HIGH.iloc[-1] for col in col_list\n",
    "    ]\n",
    "    return all(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_stocks(\n",
    "#     timeframe=\"weekly\",\n",
    "#     cutoff_date=datetime(2023, 5, 3),\n",
    "#     strategy=single_candle_span,\n",
    "#     # strategy_args={\"col_list\": [\"SMA_20_C\", \"SMA_200_C\", \"SMA_44_C\"]},\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hammer on BBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check if the latest candle is a hammer\n",
    "def hammer_on_BBL(df, kwargs=None):\n",
    "    body = df.iloc[-1].CLOSE - df.iloc[-1].OPEN\n",
    "    upper_wick = df.iloc[-1].HIGH - df.iloc[-1].CLOSE\n",
    "    lower_wick = df.iloc[-1].OPEN - df.iloc[-1].LOW\n",
    "\n",
    "    conditions = [\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        lower_wick >= 2 * body,\n",
    "        body >= 1.5 * upper_wick,\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].BBL_20_2 > df.iloc[-1].LOW,\n",
    "    ]\n",
    "\n",
    "    return all(conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_stocks(\n",
    "#     timeframe=\"weekly\",\n",
    "#     # cutoff_date=datetime(2023,4, 27),\n",
    "#     strategy=hammer_on_BBL,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Green takes out red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check if latest candle is green takes out red on BBL\n",
    "def green_engulfing_on_BBL(df, kwargs=None):\n",
    "    conditions = [\n",
    "        df.iloc[-2].CLOSE < df.iloc[-2].OPEN,\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        df.iloc[-1].LOW < df.iloc[-1].BBL_20_2 < df.iloc[-1].HIGH,\n",
    "        df.iloc[-1].CLOSE > df.iloc[-2].OPEN,\n",
    "    ]\n",
    "\n",
    "    return all(conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_stocks(\n",
    "#     symbols=\"all\",\n",
    "#     timeframe=\"weekly\",\n",
    "#     # cutoff_date=datetime(2023,3, 31),\n",
    "#     strategy=green_engulfing_on_BBL,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three rising green candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Check for three rising green candles\n",
    "def three_rising_green_candles_on_SMA20(df, kwargs=None):\n",
    "    conditions = [\n",
    "        df.iloc[-1].CLOSE > df.iloc[-1].OPEN,\n",
    "        df.iloc[-2].CLOSE > df.iloc[-2].OPEN,\n",
    "        df.iloc[-3].CLOSE > df.iloc[-3].OPEN,\n",
    "        df.iloc[-1].CLOSE > df.iloc[-2].CLOSE,\n",
    "        df.iloc[-2].CLOSE > df.iloc[-3].CLOSE,\n",
    "        df.iloc[-3].CLOSE > df.iloc[-3].SMA_20_C,\n",
    "        df.iloc[-3].LOW < df.iloc[-3].SMA_20_C,\n",
    "    ]\n",
    "\n",
    "    return all(conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_stocks(\n",
    "#     timeframe=\"weekly\",\n",
    "#     # cutoff_date=datetime(2023,4, 27),\n",
    "#     strategy=three_rising_green_candles_on_SMA20,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 SMA HALT STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_directional_crossover(df, col1, col2, days_lookback=7):\n",
    "    days_lookback = min(days_lookback + 1, df.shape[0])\n",
    "    for d in range(1, days_lookback):\n",
    "        # print(f\"Checking for {df.DATE.iloc[-d]}: {df[col1].iloc[-d]}, {df[col2].iloc[-d]}\")\n",
    "        if (\n",
    "            df[col1].iloc[-d] > df[col2].iloc[-d]\n",
    "            and df[col1].iloc[-d - 1] < df[col2].iloc[-d - 1]\n",
    "        ):\n",
    "            # print(f\"{col1} crossed over {col2} on {df.DATE.iloc[-d]} : {d} days ago\")\n",
    "            return d\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_close_under_falling_20(df, d, days_lookback=10):\n",
    "    df = df.iloc[-d - days_lookback : -d]\n",
    "    # print(df.DATE.iloc[0], df.DATE.iloc[-1])\n",
    "    # df.plot(x=\"DATE\", y=[\"CLOSE\", \"SMA_20_C\"], figsize=(15, 5))\n",
    "    # df.plot(x=\"DATE\", y=[\"CLOSE\", \"SMA_20_C\", \"SMA_20_H\"], figsize=(15, 5))\n",
    "    # print(df.SMA_20_C.is_monotonic_decreasing, df.SMA_20_H.is_monotonic_decreasing)\n",
    "    return all(\n",
    "        [\n",
    "            any(\n",
    "                [\n",
    "                    df.SMA_20_C.is_monotonic_decreasing,\n",
    "                    df.SMA_20_H.is_monotonic_decreasing,\n",
    "                    df.SMA_44_C.is_monotonic_decreasing,\n",
    "                ]\n",
    "            ),\n",
    "            any(\n",
    "                [\n",
    "                    all(df.CLOSE < df.SMA_20_H),\n",
    "                    # all(df.CLOSE < df.SMA_20_C)\n",
    "                ]\n",
    "            ),\n",
    "            # all(df.SMA_200_C < df.SMA_20_C)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# check_close_under_20(df, 15, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_close_above_20(df, d, days_lookfwd=3):\n",
    "    df = df.iloc[-d + 1 :].head(days_lookfwd)\n",
    "    # print(df)\n",
    "    # print(df.DATE.iloc[0], df.DATE.iloc[-1])\n",
    "    # df.plot(x=\"DATE\", y=[\"CLOSE\", \"SMA_20_C\"], figsize=(15, 5))\n",
    "    return all(df.CLOSE > df.SMA_20_C)  # df.SMA_20_C.is_monotonic_increasing and\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_20_200_breakout(df, days_lookback=5):\n",
    "    found = False\n",
    "    col1 = \"CLOSE\"\n",
    "    col2 = \"SMA_20_C\"\n",
    "    col3 = \"SMA_200_C\"\n",
    "    col4 = \"SMA_20_H\"\n",
    "    # df = df[:-45]\n",
    "\n",
    "    # Check for double crossover on SMA20 and SMA200 within a 3 day period\n",
    "    dc20 = check_directional_crossover(df, col1, col2, days_lookback=days_lookback)\n",
    "    if all(\n",
    "        [\n",
    "            dc20 > 0,\n",
    "            check_close_under_falling_20(df, dc20, days_lookback=30),\n",
    "            check_close_above_20(df, dc20),\n",
    "        ]\n",
    "    ):\n",
    "        found = True\n",
    "        dc200 = check_directional_crossover(df, col1, col3, days_lookback=days_lookback)\n",
    "        # print(dc20, dc200)\n",
    "\n",
    "        if all([dc200 > 0, abs(dc20 - dc200) < 3]):\n",
    "            print(\n",
    "                f\"{df.SYMBOL.iloc[0]} -> Double crossover on {df.DATE.iloc[-dc20]} : {dc20} days ago, with {df.iloc[-dc20].CDL_COLOR} candle\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"{df.SYMBOL.iloc[0]} -> SMA20 crossover on {df.DATE.iloc[-dc20]} : {dc20} days ago, with {df.iloc[-dc20].CDL_COLOR} candle\"\n",
    "            )\n",
    "            if dc200:\n",
    "                print(\n",
    "                    f\"{df.SYMBOL.iloc[0]} -> SMA 200 crossover: {df.DATE.iloc[-dc200]} : {dc200} days ago, with {df.iloc[-dc200].CDL_COLOR} candle\"\n",
    "                )\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_3_green_on_sma20(df):\n",
    "    crossover = check_directional_crossover(df, \"CLOSE\", \"SMA_20_C\", days_lookback=15)\n",
    "    if all(\n",
    "        [\n",
    "            crossover > 2,\n",
    "            df.iloc[-crossover].CDL_COLOR == \"green\",\n",
    "            df.iloc[-crossover + 1].CDL_COLOR == \"green\",\n",
    "            df.iloc[-crossover + 2].CDL_COLOR == \"green\",\n",
    "            df.iloc[-crossover + 1].CLOSE > df.iloc[-crossover].CLOSE,\n",
    "            df.iloc[-crossover + 2].CLOSE > df.iloc[-crossover + 1].CLOSE,\n",
    "            df.iloc[-crossover + 2].CLOSE < df.iloc[-crossover + 2].BBU_20_2,\n",
    "            # df.iloc[-crossover].BBB_20_2 > 8,\n",
    "            df.iloc[-crossover + 1].SMA_20_C > df.iloc[-crossover - 1].SMA_20_C\n",
    "            # crossover > 10,\n",
    "        ]\n",
    "    ):\n",
    "        max_close = max(df[-crossover + 1 :].CLOSE)\n",
    "        perc_movement = (\n",
    "            100\n",
    "            * (max_close - df.iloc[-crossover + 2].CLOSE)\n",
    "            / df.iloc[-crossover + 2].CLOSE\n",
    "        )\n",
    "        print(\n",
    "            f\"{df.SYMBOL.iloc[0]} -> SMA20 crossover on {df.DATE.iloc[-crossover]} : BBB = {df.BBB_20_2.iloc[-crossover]:0.2f} : Moved {perc_movement:.2f}%, upto {max_close}\"\n",
    "        )\n",
    "    # else:\n",
    "    #     print(crossover)\n",
    "\n",
    "\n",
    "# df[-crossover-5:-crossover + 5][[\"DATE\", \"CLOSE\", \"SMA_20_C\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in df500:\n",
    "#     df = get_symbol_data(symbol)\n",
    "#     if df is not None:\n",
    "#         check_3_green_on_sma20(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_symbol_data(\"PNB\")\n",
    "# window = 500\n",
    "# df.tail(window).plot(\n",
    "#     x=\"DATE\",\n",
    "#     y=[\n",
    "#         # \"BBU_20_2\",\n",
    "#         # \"BBM_20_2\",\n",
    "#         # \"BBL_20_2\",\n",
    "#         \"BBB_20_2\",\n",
    "#         # \"BBP_20_2\",\n",
    "#         \"CLOSE\"\n",
    "#     ],\n",
    "#     figsize=(18, 15),\n",
    "# )\n",
    "# df.tail(window).plot(\n",
    "#     x=\"DATE\",\n",
    "#     y=[\n",
    "#         \"CLOSE\"\n",
    "#     ],\n",
    "#     figsize=(18, 5),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMA 20 & SMA 200 Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find stocks with SMA20 and SMA44 single candle span\n",
    "# for symbol in df500:\n",
    "#     df = get_symbol_data(symbol)\n",
    "#     if df is not None:\n",
    "#         check_single_candle_span(\n",
    "#             df, col_list=[\"SMA_20_C\", \"SMA_44_C\", \"SMA_200_C\"], days_lookback=2\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find stocks with 20ma crossover preceded by time under a falling SMA20\n",
    "# for symbol in df500:\n",
    "#     df = get_symbol_data(symbol)\n",
    "#     if df is not None:\n",
    "#         a = check_20_200_breakout(df)\n",
    "#         if a:\n",
    "#             b = check_single_candle_span(\n",
    "#                 df, col_list=[\"SMA_20_C\", \"SMA_44_C\", \"SMA_200_C\"], days_lookback=5\n",
    "#             )\n",
    "#             print(\"-\" * 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALLTIME HIGH STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_historical_minmax(df, min_steps_back=30, mode=None):\n",
    "    if mode is None or mode == \"all\":\n",
    "        mode = [\"min\", \"max\"]\n",
    "\n",
    "    if \"DATE\" not in df.columns:\n",
    "        df[\"DATE\"] = df.index\n",
    "\n",
    "    max_steps = len(df)\n",
    "    if max_steps > min_steps_back:\n",
    "        if \"max\" in mode or mode == \"max\":\n",
    "            # Search for historical high\n",
    "            last_is_max = True\n",
    "            steps_back = 1\n",
    "            while last_is_max:\n",
    "                steps_back += 1\n",
    "                if steps_back > max_steps:\n",
    "                    print(\n",
    "                        f\"{df.SYMBOL.iloc[-1]}: ALL TIME HIGH on {df.DATE.iloc[-1].date()} closed at {df.CLOSE.iloc[-1]}\"\n",
    "                    )\n",
    "                    return\n",
    "                last_is_max = df.CLOSE.iloc[-1] >= df.HIGH.iloc[-steps_back]\n",
    "\n",
    "            if steps_back >= min_steps_back:\n",
    "                print(\n",
    "                    f\"{df.SYMBOL.iloc[-1]} CLOSE -> {df.CLOSE.iloc[-1]} : New high of {steps_back} sessions, since HIGH of {df.HIGH.iloc[-steps_back]} on {df.DATE.iloc[-steps_back].date()}\"\n",
    "                )\n",
    "\n",
    "        if \"min\" in mode or mode == \"min\":\n",
    "            # Search for historical low\n",
    "            last_is_min = True\n",
    "            steps_back = 1\n",
    "            while last_is_min:\n",
    "                steps_back += 1\n",
    "                if steps_back > max_steps:\n",
    "                    print(\n",
    "                        f\"{df.SYMBOL.iloc[-1]}: ALL TIME LOW on {df.DATE.iloc[-1].date()} closed at {df.CLOSE.iloc[-1]}\"\n",
    "                    )\n",
    "                    return\n",
    "                last_is_min = df.CLOSE.iloc[-1] <= df.LOW.iloc[-steps_back]\n",
    "\n",
    "            if steps_back >= min_steps_back:\n",
    "                print(\n",
    "                    f\"{df.SYMBOL.iloc[-1]} CLOSE -> {df.CLOSE.iloc[-1]} : New low of {steps_back} sessions, since LOW of {df.LOW.iloc[-steps_back]} on {df.DATE.iloc[-steps_back].date()}\"\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist: c:\\MyData\\TechWork\\stocksurfer\\stocksurfer\\..\\Data\\Bhavcopy\\Processed\\BAJAJFINSV.csv\n"
     ]
    }
   ],
   "source": [
    "symbol = \"BAJAJFINSV\"\n",
    "file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "if not file_path.exists():\n",
    "    print(f\"File does not exist: {file_path}\")\n",
    "else:\n",
    "    print(f\"File exists: {file_path}\")\n",
    "    df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "    # Convert daily data to monthly data\n",
    "    df_monthly = df.resample(\"M\", on=\"DATE\").agg(\n",
    "        {\n",
    "            \"OPEN\": \"first\",\n",
    "            \"HIGH\": \"max\",\n",
    "            \"LOW\": \"min\",\n",
    "            \"CLOSE\": \"last\",\n",
    "            \"SYMBOL\": \"first\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # check_historical_minmax(df, min_steps_back=4, mode=None)\n",
    "    # check_historical_minmax(df_monthly, min_steps_back=4, mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in df500:\n",
    "#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "#     if file_path.exists():\n",
    "#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "#         # Convert daily data to monthly data\n",
    "#         df_monthly = df.resample(\"M\", on=\"DATE\").agg(\n",
    "#             {\n",
    "#                 \"OPEN\": \"first\",\n",
    "#                 \"HIGH\": \"max\",\n",
    "#                 \"LOW\": \"min\",\n",
    "#                 \"CLOSE\": \"last\",\n",
    "#                 \"SYMBOL\": \"first\",\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         # check_historical_minmax(df, min_steps_back=30, mode=\"max\")\n",
    "#         check_historical_minmax(df_monthly, min_steps_back=36, mode=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all csv files in raw_data_dir\n",
    "# csv_files = [f for f in raw_data_dir.iterdir() if f.suffix == '.csv']\n",
    "\n",
    "# for file in csv_files:\n",
    "#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "#     if os.path.exists(file_path):\n",
    "#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "\n",
    "#         # Convert daily data to monthly data\n",
    "#         df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n",
    "\n",
    "#         # check_historical_minmax(df, min_steps_back=300, mode=\"max\")\n",
    "#         check_historical_minmax(df_monthly, min_steps_back=60, mode=\"max\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movement in a band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_movement_within_band(df, band_perc=5, steps_lookback=20):\n",
    "    steps_lookback = min(steps_lookback + 1, df.shape[0])\n",
    "    max_steps = len(df)\n",
    "\n",
    "    band_max = df.CLOSE.iloc[-1] * (1 + band_perc / 100)\n",
    "    band_min = df.CLOSE.iloc[-1] * (1 - band_perc / 100)\n",
    "\n",
    "    in_band = True\n",
    "    steps_back = 1\n",
    "    while in_band:\n",
    "        steps_back += 1\n",
    "        if steps_back > max_steps:\n",
    "            print(\n",
    "                f\"{df.SYMBOL.iloc[-1]}: Within band of {band_perc}% for {steps_back-1} sessions for band: {band_min:0.2f} to {band_max:0.2f}\"\n",
    "            )\n",
    "            return\n",
    "        in_band = (df.CLOSE.iloc[-steps_back] <= band_max) and (\n",
    "            df.CLOSE.iloc[-steps_back] >= band_min\n",
    "        )\n",
    "\n",
    "    if steps_back >= steps_lookback:\n",
    "        print(\n",
    "            f\"{df.SYMBOL.iloc[-1]} CLOSE -> {df.CLOSE.iloc[-1]} : Within band of {band_perc}% for {steps_back-1} sessions for band: {band_min:0.2f} to {band_max:0.2f}\"\n",
    "        )\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol = \"VAIBHAVGBL\"\n",
    "# file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "# if not os.path.exists(file_path):\n",
    "#     print(f\"File does not exist: {file_path}\")\n",
    "# else:\n",
    "#     print(f\"File exists: {file_path}\")\n",
    "#     df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "#     df = df.query(\"DATE < '2022-08-27'\")\n",
    "#     check_movement_within_band(df, band_perc=5, steps_lookback=20)\n",
    "\n",
    "# Convert daily data to monthly data\n",
    "# df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in df500:\n",
    "#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "#     if os.path.exists(file_path):\n",
    "#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "\n",
    "#         check_movement_within_band(df, band_perc=3, steps_lookback=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_3_green_on_SMA(df, sma_period=20):\n",
    "\n",
    "#     if df.shape[0] < sma_period:\n",
    "#         return\n",
    "\n",
    "#     if all([\n",
    "#         df.OPEN.iloc[-3] < df.SMA_20_C.iloc[-3] < df.CLOSE.iloc[-3],\n",
    "#         df.OPEN.iloc[-2] < df.CLOSE.iloc[-2],\n",
    "#         df.OPEN.iloc[-1] < df.CLOSE.iloc[-1],\n",
    "#         df.CLOSE.iloc[-1] > df.CLOSE.iloc[-2] > df.CLOSE.iloc[-3],\n",
    "#     ]): # 3 green candles on SMA\n",
    "\n",
    "#         print(f\"{df.SYMBOL.iloc[-1]}: 3 green candles on SMA 20 on {df.DATE.iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all csv files in raw_data_dir\n",
    "# csv_files = [f for f in os.listdir(processed_data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# for file in csv_files:\n",
    "#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n",
    "#     if os.path.exists(file_path):\n",
    "#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n",
    "\n",
    "#         # Convert daily data to monthly data\n",
    "#         # df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n",
    "\n",
    "#         # Convert daily data to weekly data\n",
    "#         df_weekly = df.resample('W', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n",
    "#         df_weekly['SMA_20_C'] = df_weekly.CLOSE.rolling(20).mean()\n",
    "#         if \"DATE\" not in df_weekly.columns:\n",
    "#             df_weekly[\"DATE\"] = df_weekly.index\n",
    "\n",
    "#         check_3_green_on_SMA(df_weekly, sma_period=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download csv from URL\n",
    "# url = r\"https://www.nseindia.com/api/equity-stockIndices?csv=true&index=SECURITIES%20IN%20F%26O\"\n",
    "# df = pd.read_csv(url)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# # Download csv from URL using requests\n",
    "# url = r\"https://www.nseindia.com/api/equity-stockIndices?csv=true&index=SECURITIES%20IN%20F%26O\"\n",
    "# requests.get(url).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nseindia.com/market-data/live-equity-market\n",
    "\n",
    "# https://www.nseindia.com/api/equity-stockIndices?csv=true&index=NIFTY%20SMALLCAP%2050\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_cap = 200000\n",
    "# win_rate = 0.6\n",
    "# one_trade_perc = 0.02\n",
    "\n",
    "# for i in range(200):\n",
    "#     if random.random() < win_rate:\n",
    "#         init_cap = init_cap * (1 + one_trade_perc)\n",
    "#     else:\n",
    "#         init_cap = init_cap * (1 - one_trade_perc)\n",
    "\n",
    "# print(f'{init_cap:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
