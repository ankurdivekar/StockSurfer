{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# technicals\n",
    "\n",
    "> This module implements various methods for adding several technical indicators and metrics to the raw bhavcopy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp technicals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas_ta as pdta\n",
    "import nbdev\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "from stocksurfer.scrapers import fetch_bhavcopy_data_for_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "base_path = nbdev.config.get_config().lib_path\n",
    "raw_data_dir = base_path / \"../Data/Bhavcopy/Raw\"\n",
    "processed_data_dir = base_path / \"../Data/Bhavcopy/Processed\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bhavcopy Utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load multiple bhavcopy files and concatenate them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def load_multiple_bhavcopy(files_to_load):\n",
    "    \n",
    "    bhavcopy_dtypes = {\n",
    "        \"SYMBOL\": \"string\",\n",
    "        \"SERIES\": \"string\",\n",
    "        \"OPEN\": \"float64\",\n",
    "        \"HIGH\": \"float64\",\n",
    "        \"LOW\": \"float64\",\n",
    "        \"CLOSE\": \"float64\",\n",
    "        \"TOTTRDQTY\": \"int64\",\n",
    "        \"TOTTRDVAL\": \"float64\",\n",
    "        \"TIMESTAMP\": \"string\",\n",
    "        \"TOTALTRADES\": \"int64\",\n",
    "        # \"ISIN\": 'string',\n",
    "        # \"Unnamed: 13\": 'string',\n",
    "    }\n",
    "\n",
    "    bhavcopy_usecols = [\n",
    "        \"SYMBOL\",\n",
    "        \"SERIES\",\n",
    "        \"OPEN\",\n",
    "        \"HIGH\",\n",
    "        \"LOW\",\n",
    "        \"CLOSE\",\n",
    "        \"TOTTRDQTY\",\n",
    "        \"TOTTRDVAL\",\n",
    "        \"TIMESTAMP\",\n",
    "        \"TOTALTRADES\",\n",
    "    ]\n",
    "    \n",
    "    return pd.concat(\n",
    "            [\n",
    "                pd.read_csv(\n",
    "                    f,\n",
    "                    dtype=bhavcopy_dtypes,\n",
    "                    usecols=bhavcopy_usecols,\n",
    "                    parse_dates=[\"TIMESTAMP\"],\n",
    "                    dayfirst=False,\n",
    "                )\n",
    "                for f in files_to_load\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all raw bhavcopy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_raw_bhavcopy_data(start_date: datetime=None, end_date:datetime.datetime=None) -> pd.DataFrame:\n",
    "    \n",
    "    if start_date:\n",
    "        end_date = end_date or datetime.datetime.today()\n",
    "        # Get list of date from bhavcopy_date till today\n",
    "        date_list = pd.date_range(start_date, end_date).tolist()\n",
    "        \n",
    "        files_to_load = []\n",
    "        for d in date_list:\n",
    "            # Get Year, Month, Day\n",
    "            year = d.year\n",
    "            month = d.strftime(\"%B\").upper()[:3]\n",
    "            day = d.date().strftime(\"%d\")\n",
    "            file_name = f\"cm{day:0>2}{month}{year}bhav.csv\"\n",
    "            file_path = raw_data_dir / file_name\n",
    "            if file_path.exists():\n",
    "                files_to_load.append(file_path)\n",
    "        return load_multiple_bhavcopy(files_to_load)\n",
    "    \n",
    "    else:\n",
    "        csv_files = [x for x in raw_data_dir.iterdir() if x.suffix == \".csv\"]\n",
    "\n",
    "        # Read all the csv files and concatenate them into one dataframe\n",
    "        # TODO filter out by end_date\n",
    "        return load_multiple_bhavcopy(csv_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess bhavcopy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def preprocess(df):\n",
    "    return (\n",
    "        df.pipe(lambda x: x[x[\"SERIES\"] == \"EQ\"])\n",
    "        .assign(\n",
    "            DATE=pd.to_datetime(df.TIMESTAMP, format=\"%d-%b-%Y\").dt.date,\n",
    "            # DAY_OF_WEEK=pd.to_datetime(df.TIMESTAMP, format=\"%d-%b-%Y\").dt.day_name(),\n",
    "            # WEEK_NUM=pd.to_datetime(df.TIMESTAMP, format=\"%d-%b-%Y\").dt.isocalendar().week,\n",
    "        )\n",
    "        .drop(\n",
    "            columns=[\n",
    "                \"TIMESTAMP\",\n",
    "            ]\n",
    "        )\n",
    "        .sort_values([\"SYMBOL\", \"DATE\"])\n",
    "        .reset_index(drop=True)\n",
    "        # .set_index(\"DATE\")\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical analysis utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Generate simple moving average data\n",
    "def get_sma(df_symbol, period=20, metric=\"CLOSE\"):\n",
    "    metric_col = f\"SMA_{period}_{metric.upper()[0]}\"\n",
    "    \n",
    "    if metric.upper() not in [\"CLOSE\", \"OPEN\", \"HIGH\", \"LOW\"]:\n",
    "        raise ValueError(f\"Invalid metric: {metric}. Valid metrics are: CLOSE, OPEN, HIGH, LOW\")\n",
    "    elif len(df_symbol) < period + 1:\n",
    "        df_symbol[metric_col] = np.nan\n",
    "        return df_symbol\n",
    "    else:\n",
    "        return pd.concat(\n",
    "            [\n",
    "                df_symbol,\n",
    "                pdta.sma(df_symbol[metric], length=period).rename(\n",
    "                    f\"SMA_{period}_{metric.upper()[0]}\"\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Bollinger bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Generate bollinger bands data\n",
    "def get_bollinger_bands(df_symbol, period=20, std=2):\n",
    "    if len(df_symbol) >= period:\n",
    "        return pd.concat(\n",
    "            [\n",
    "                df_symbol,\n",
    "                pdta.bbands(df_symbol.CLOSE, length=period, std=std).rename(\n",
    "                    columns={\n",
    "                        f\"BBU_{period}_{std:.1f}\": f\"BBU_{period}_{std}\",\n",
    "                        f\"BBM_{period}_{std:.1f}\": f\"BBM_{period}_{std}\",\n",
    "                        f\"BBL_{period}_{std:.1f}\": f\"BBL_{period}_{std}\",\n",
    "                        f\"BBB_{period}_{std:.1f}\": f\"BBB_{period}_{std}\",\n",
    "                        f\"BBP_{period}_{std:.1f}\": f\"BBP_{period}_{std}\",\n",
    "                    }\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "    df_symbol[f\"BBU_{period}_{std}\"] = np.nan\n",
    "    df_symbol[f\"BBM_{period}_{std}\"] = np.nan\n",
    "    df_symbol[f\"BBL_{period}_{std}\"] = np.nan\n",
    "    df_symbol[f\"BBB_{period}_{std}\"] = np.nan\n",
    "    df_symbol[f\"BBP_{period}_{std}\"] = np.nan\n",
    "    return df_symbol"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Donchian channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Generate donchian channel data\n",
    "def get_donchian(df_symbol, upper=22, lower=66):\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df_symbol,\n",
    "            pdta.donchian(\n",
    "                df_symbol.HIGH, df_symbol.LOW, lower_length=66, upper_length=22\n",
    "            )\n",
    "            # .rename(\n",
    "            #     columns={\n",
    "            #         f\"DCL_{lower}_{upper}\": f\"DONCHIAN_L{lower}\",\n",
    "            #         f\"DCU_{lower}_{upper}\": f\"DONCHIAN_U{upper}\"})\n",
    "            .drop(columns=[f\"DCM_{lower}_{upper}\"]),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Supertrend indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Generate supertrend data\n",
    "def get_supertrend(df_symbol, period=12, multiplier=3):\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df_symbol,\n",
    "            pdta.supertrend(\n",
    "                df_symbol.HIGH,\n",
    "                df_symbol.LOW,\n",
    "                df_symbol.CLOSE,\n",
    "                length=period,\n",
    "                multiplier=multiplier,\n",
    "            )\n",
    "            .drop(\n",
    "                columns=[\n",
    "                    f\"SUPERT_{period}_{multiplier:.1f}\",\n",
    "                    f\"SUPERTl_{period}_{multiplier:.1f}\",\n",
    "                    f\"SUPERTs_{period}_{multiplier:.1f}\",\n",
    "                ]\n",
    "            )\n",
    "            .rename(\n",
    "                columns={\n",
    "                    f\"SUPERTd_{period}_{multiplier:.1f}\": f\"ST_{period}_{multiplier}\"\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get candlestick properties data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def add_candle_stats(df_symbol):\n",
    "    return df_symbol.assign(\n",
    "        CDL_COLOR=df_symbol.apply(\n",
    "            lambda x: \"green\" if x.CLOSE > x.OPEN else \"red\", axis=1\n",
    "        ).astype(\"string\"),\n",
    "        CDL_SIZE=abs(df_symbol.CLOSE - df_symbol.OPEN),\n",
    "        TOPWICK_SIZE=df_symbol.HIGH - df_symbol[[\"OPEN\", \"CLOSE\"]].max(axis=1),\n",
    "        BOTWICK_SIZE=df_symbol[[\"OPEN\", \"CLOSE\"]].min(axis=1) - df_symbol.LOW,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all technical indicator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Generate all technicals for a symbol data\n",
    "def add_all_technicals(df_symbol):\n",
    "    return (\n",
    "        df_symbol.sort_values([\"SYMBOL\", \"DATE\"])\n",
    "        .reset_index(drop=True)\n",
    "        # Add SMA\n",
    "        .pipe(get_sma, period=20, metric=\"CLOSE\")\n",
    "        .pipe(get_sma, period=20, metric=\"HIGH\")\n",
    "        .pipe(get_sma, period=44, metric=\"CLOSE\")\n",
    "        .pipe(get_sma, period=200, metric=\"CLOSE\")\n",
    "        # Add Bollinger bands\n",
    "        .pipe(get_bollinger_bands)\n",
    "        # Add Donchian channel\n",
    "        # .pipe(get_donchian)\n",
    "        # Add supertrend data\n",
    "        # .pipe(get_supertrend, period=12, multiplier=3)\n",
    "        # .pipe(get_supertrend, period=11, multiplier=2)\n",
    "        # .pipe(get_supertrend, period=10, multiplier=1)\n",
    "        # Add candle properties data\n",
    "        # .pipe(add_candle_stats)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all symbols and add technicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def process_and_save_symbol_data(df):\n",
    "    df = add_all_technicals(df)\n",
    "    file_path = processed_data_dir / f\"{df.SYMBOL.iloc[-1]}.parquet\"\n",
    "    df.to_parquet(file_path, index=False)\n",
    "    print(f\"Saved {file_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def rebuild_all_symbols_data():\n",
    "    df = get_raw_bhavcopy_data()\n",
    "    df = preprocess(df)\n",
    "    \n",
    "    # Recursively delete all files and directories inside the processed data directory\n",
    "    _ = [\n",
    "        shutil.rmtree(f) if f.is_dir() else f.unlink()\n",
    "        for f in processed_data_dir.iterdir()\n",
    "    ]\n",
    "\n",
    "    for symbol, df_symbol in df.groupby(\"SYMBOL\"):\n",
    "        if len(df_symbol) > 200:\n",
    "            process_and_save_symbol_data(df_symbol)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_all_symbols_data():\n",
    "    # Define date range\n",
    "    start_date = (\n",
    "        pd.read_parquet(processed_data_dir / \"INFY.parquet\")\n",
    "        .sort_values([\"DATE\"])\n",
    "        .reset_index(drop=True)\n",
    "        .DATE.iloc[-2]\n",
    "    )\n",
    "    end_date = datetime.datetime.now().date()#-datetime.timedelta(days=15)\n",
    "    print(start_date, end_date)\n",
    "\n",
    "    # Fetch latest data from NSE\n",
    "    fetch_bhavcopy_data_for_range(start_date, end_date)\n",
    "\n",
    "    df = preprocess(get_raw_bhavcopy_data(start_date=start_date))\n",
    "    new_rows_per_symbol = df.shape[0]/df.SYMBOL.nunique()\n",
    "    \n",
    "    if new_rows_per_symbol < 3:\n",
    "        print(\"No new data to update\")\n",
    "    else:\n",
    "        for symbol, df_symbol in df.groupby(\"SYMBOL\"):\n",
    "            pq = processed_data_dir / f\"{symbol}.parquet\"\n",
    "            if pq.exists():\n",
    "                # Load earlier data\n",
    "                old_df = pd.read_parquet(pq)\n",
    "                old_df = old_df.drop(\n",
    "                    columns=[\n",
    "                        x\n",
    "                        for x in old_df.columns\n",
    "                        if x\n",
    "                        not in [\n",
    "                            \"SYMBOL\",\n",
    "                            \"SERIES\",\n",
    "                            \"OPEN\",\n",
    "                            \"HIGH\",\n",
    "                            \"LOW\",\n",
    "                            \"CLOSE\",\n",
    "                            \"TOTTRDQTY\",\n",
    "                            \"TOTTRDVAL\",\n",
    "                            \"TOTALTRADES\",\n",
    "                            \"DATE\",\n",
    "                        ]\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                new_df = (\n",
    "                    pd.concat([old_df, df_symbol])\n",
    "                    .sort_values([\"DATE\"])\n",
    "                    .drop_duplicates(subset=[\"DATE\"], keep=\"first\")\n",
    "                    .reset_index(drop=True)\n",
    "                )\n",
    "                #TODO: new_df has duplicates\n",
    "                # print(old_df.shape)\n",
    "                # print(df_symbol.shape)\n",
    "                process_and_save_symbol_data(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-27 2023-05-01\n",
      "--------------------------------------------------\n",
      "Fetching data for 4 days\n",
      "File cm27APR2023bhav.csv.zip already exists.. unzipping\n",
      "File cm28APR2023bhav.csv.zip already exists.. unzipping\n",
      "Skipping 2023-04-29 as it is a weekend\n",
      "Skipping 2023-04-30 as it is a weekend\n",
      "Skipping 2023-05-01 as it is a holiday: Maharashtra Day\n",
      "Bhavcopy data download complete\n",
      "--------------------------------------------------\n",
      "No new data to update\n"
     ]
    }
   ],
   "source": [
    "update_all_symbols_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
