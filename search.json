[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "stocksurfer",
    "section": "",
    "text": "Install: Currently not pip installable. Under heavy development. Until then, clone the repo and run pip install -e . from the root directory."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "stocksurfer",
    "section": "How to use",
    "text": "How to use\n\nfrom datetime import datetime\n\nGet the latest NSE data\n\n# Define date range\nstart_date = datetime(2023,4, 1)\nend_date = datetime.now()\n\n# Fetch data from NSE\nfetch_bhavcopy_data_for_range(start_date, end_date)\n\nSkipping 2023-04-01 as it is a weekend\nSkipping 2023-04-02 as it is a weekend\nFile cm03APR2023bhav.csv.zip already exists.. unzipping\nSkipping 2023-04-04 as it is a holiday: Mahavir Jayanti\nFile cm05APR2023bhav.csv.zip already exists.. unzipping\nFile cm06APR2023bhav.csv.zip already exists.. unzipping\nSkipping 2023-04-07 as it is a holiday: Good Friday\nBhavcopy data download complete\n\n\nGet list of stocks in ASM and GSM\n\n# get_blocklist()\n\nGenerate stock data with technical indicators added\n\n# process_all_symbols()"
  },
  {
    "objectID": "scrapers.html",
    "href": "scrapers.html",
    "title": "scrapers",
    "section": "",
    "text": "source\n\n\n\n get_request_headers ()"
  },
  {
    "objectID": "scrapers.html#bhavcopy-data-scraper",
    "href": "scrapers.html#bhavcopy-data-scraper",
    "title": "scrapers",
    "section": "Bhavcopy data scraper",
    "text": "Bhavcopy data scraper\n\nsource\n\nsave_daily_bhavcopy\n\n save_daily_bhavcopy (d, random_delay=True)\n\n\nsource\n\n\nfetch_bhavcopy_data_for_range\n\n fetch_bhavcopy_data_for_range (start_date, end_date)"
  },
  {
    "objectID": "scrapers.html#misc-scrapers",
    "href": "scrapers.html#misc-scrapers",
    "title": "scrapers",
    "section": "Misc scrapers",
    "text": "Misc scrapers\nGet list of NSE Holidays\n\nsource\n\nget_holidays_table\n\n get_holidays_table (segment:str='Equities')\n\n\nsource\n\n\nscrape_nse_holidays\n\n scrape_nse_holidays (segment:str)\n\nGeneral scraper for list of stocks in various segments\n\nsource\n\n\nscrape_symbol_list\n\n scrape_symbol_list (file_url:str, file_path:str=None)\n\nGet list of stocks in ASM and GSM\n\nsource\n\n\nscrape_gsm_list\n\n scrape_gsm_list ()\n\n\nsource\n\n\nscrape_asm_list\n\n scrape_asm_list ()\n\nGet list of illiquid stocks\n\nsource\n\n\nscrape_illiquid_list\n\n scrape_illiquid_list ()\n\nGet list of all stocks to be ignored\n\nsource\n\n\nget_blocklist\n\n get_blocklist ()\n\nGet list of stocks in insider trading info\n\nsource\n\n\nget_insider_trading_list\n\n get_insider_trading_list ()"
  },
  {
    "objectID": "strategies.html",
    "href": "strategies.html",
    "title": "strategies",
    "section": "",
    "text": "20 SMA HALT STRATEGY\n\nsource\n\ncheck_directional_crossover\n\n check_directional_crossover (df, col1, col2, days_lookback=7)\n\n\nsource\n\n\nget_symbol_data\n\n get_symbol_data (symbol)\n\n\nsource\n\n\ncheck_close_under_falling_20\n\n check_close_under_falling_20 (df, d, days_lookback=10)\n\n\nsource\n\n\ncheck_close_above_20\n\n check_close_above_20 (df, d, days_lookfwd=3)\n\n\nsource\n\n\ncheck_20_200_breakout\n\n check_20_200_breakout (df, days_lookback=5)\n\n\nsource\n\n\ncheck_single_candle_span\n\n check_single_candle_span (df, col_list=['SMA_20_C', 'SMA_200_C'],\n                           days_lookback=2)\n\n\ndef check_3_green_on_sma20(df):\n    crossover = check_directional_crossover(df, \"CLOSE\", \"SMA_20_C\", days_lookback=15)\n    if all([\n        crossover > 2,\n        df.iloc[-crossover].CDL_COLOR == \"green\",\n        df.iloc[-crossover+1].CDL_COLOR == \"green\",\n        df.iloc[-crossover+2].CDL_COLOR == \"green\",\n        df.iloc[-crossover+1].CLOSE > df.iloc[-crossover].CLOSE,\n        df.iloc[-crossover+2].CLOSE > df.iloc[-crossover+1].CLOSE,\n        df.iloc[-crossover+2].CLOSE < df.iloc[-crossover+2].BBU_20_2,\n        # df.iloc[-crossover].BBB_20_2 > 8,\n        df.iloc[-crossover+1].SMA_20_C > df.iloc[-crossover-1].SMA_20_C\n        # crossover > 10,\n    ]):\n        max_close = max(df[-crossover+1:].CLOSE)\n        perc_movement = 100* (max_close - df.iloc[-crossover+2].CLOSE) / df.iloc[-crossover+2].CLOSE\n        print(f\"{df.SYMBOL.iloc[0]} -> SMA20 crossover on {df.DATE.iloc[-crossover]} : BBB = {df.BBB_20_2.iloc[-crossover]:0.2f} : Moved {perc_movement:.2f}%, upto {max_close}\")\n    # else:\n    #     print(crossover)\n\n# df[-crossover-5:-crossover + 5][[\"DATE\", \"CLOSE\", \"SMA_20_C\"]]\n\n\n# for symbol in df500:\n#     df = get_symbol_data(symbol)\n#     if df is not None:\n#         check_3_green_on_sma20(df)\n\n\n# df = get_symbol_data(\"PNB\")\n# window = 500\n# df.tail(window).plot(\n#     x=\"DATE\",\n#     y=[\n#         # \"BBU_20_2\",\n#         # \"BBM_20_2\",\n#         # \"BBL_20_2\",\n#         \"BBB_20_2\",\n#         # \"BBP_20_2\",\n#         \"CLOSE\"\n#     ],\n#     figsize=(18, 15),\n# )\n# df.tail(window).plot(\n#     x=\"DATE\",\n#     y=[\n#         \"CLOSE\"\n#     ],\n#     figsize=(18, 5),\n# )\n\nSMA 20 & SMA 200 Strategies\n\n# Find stocks with SMA20 and SMA44 single candle span\n# for symbol in df500:\n#     df = get_symbol_data(symbol)\n#     if df is not None:\n#         check_single_candle_span(\n#             df, col_list=[\"SMA_20_C\", \"SMA_44_C\", \"SMA_200_C\"], days_lookback=2\n#         )\n\n\n# Find stocks with 20ma crossover preceded by time under a falling SMA20\n# for symbol in df500:\n#     df = get_symbol_data(symbol)\n#     if df is not None:\n#         a = check_20_200_breakout(df)\n#         if a:\n#             b = check_single_candle_span(\n#                 df, col_list=[\"SMA_20_C\", \"SMA_44_C\", \"SMA_200_C\"], days_lookback=5\n#             )\n#             print(\"-\" * 100)\n\nALLTIME HIGH STRATEGY\n\nsource\n\n\ncheck_historical_minmax\n\n check_historical_minmax (df, min_steps_back=30, mode=None)\n\n\nsymbol = \"BAJAJFINSV\"\nfile_path = base_path / processed_data_dir / f\"{symbol}.csv\"\nif not file_path.exists():\n    print(f\"File does not exist: {file_path}\")\nelse:\n    print(f\"File exists: {file_path}\")\n    df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n    # Convert daily data to monthly data\n    df_monthly = df.resample(\"M\", on=\"DATE\").agg(\n        {\n            \"OPEN\": \"first\",\n            \"HIGH\": \"max\",\n            \"LOW\": \"min\",\n            \"CLOSE\": \"last\",\n            \"SYMBOL\": \"first\",\n        }\n    )\n\n    check_historical_minmax(df, min_steps_back=4, mode=None)\n    # check_historical_minmax(df_monthly, min_steps_back=4, mode=None)\n\nFile does not exist: c:\\MyData\\TechWork\\stocksurfer\\stocksurfer\\..\\Data\\Bhavcopy\\Processed\\BAJAJFINSV.csv\n\n\n\n# for symbol in df500:\n#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n#     if file_path.exists():\n#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n#         # Convert daily data to monthly data\n#         df_monthly = df.resample(\"M\", on=\"DATE\").agg(\n#             {\n#                 \"OPEN\": \"first\",\n#                 \"HIGH\": \"max\",\n#                 \"LOW\": \"min\",\n#                 \"CLOSE\": \"last\",\n#                 \"SYMBOL\": \"first\",\n#             }\n#         )\n\n#         # check_historical_minmax(df, min_steps_back=30, mode=\"max\")\n#         check_historical_minmax(df_monthly, min_steps_back=36, mode=\"all\")\n\n\n# Get list of all csv files in raw_data_dir\n# csv_files = [f for f in raw_data_dir.iterdir() if f.suffix == '.csv']\n\n# for file in csv_files:\n#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n#     if os.path.exists(file_path):\n#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n\n#         # Convert daily data to monthly data\n#         df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n\n#         # check_historical_minmax(df, min_steps_back=300, mode=\"max\")\n#         check_historical_minmax(df_monthly, min_steps_back=60, mode=\"max\")\n\nMovement in a band\n\ndef check_movement_within_band(df, band_perc=5, steps_lookback=20):\n    steps_lookback = min(steps_lookback + 1, df.shape[0])\n    max_steps = len(df)\n\n    band_max = df.CLOSE.iloc[-1] * (1 + band_perc / 100)\n    band_min = df.CLOSE.iloc[-1] * (1 - band_perc / 100)\n\n    in_band = True\n    steps_back = 1\n    while in_band:\n        steps_back += 1\n        if steps_back > max_steps:\n            print(\n                f\"{df.SYMBOL.iloc[-1]}: Within band of {band_perc}% for {steps_back-1} sessions for band: {band_min:0.2f} to {band_max:0.2f}\"\n            )\n            return\n        in_band = (df.CLOSE.iloc[-steps_back] <= band_max) and (\n            df.CLOSE.iloc[-steps_back] >= band_min\n        )\n\n    if steps_back >= steps_lookback:\n        print(\n            f\"{df.SYMBOL.iloc[-1]} CLOSE -> {df.CLOSE.iloc[-1]} : Within band of {band_perc}% for {steps_back-1} sessions for band: {band_min:0.2f} to {band_max:0.2f}\"\n        )\n        return\n\n\n# symbol = \"VAIBHAVGBL\"\n# file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n# if not os.path.exists(file_path):\n#     print(f\"File does not exist: {file_path}\")\n# else:\n#     print(f\"File exists: {file_path}\")\n#     df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n#     df = df.query(\"DATE < '2022-08-27'\")\n#     check_movement_within_band(df, band_perc=5, steps_lookback=20)\n\n# Convert daily data to monthly data\n# df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n\n\n# for symbol in df500:\n#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n#     if os.path.exists(file_path):\n#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n\n#         check_movement_within_band(df, band_perc=3, steps_lookback=20)\n\n\n# def check_3_green_on_SMA(df, sma_period=20):\n\n#     if df.shape[0] < sma_period:\n#         return\n\n#     if all([\n#         df.OPEN.iloc[-3] < df.SMA_20_C.iloc[-3] < df.CLOSE.iloc[-3],\n#         df.OPEN.iloc[-2] < df.CLOSE.iloc[-2],\n#         df.OPEN.iloc[-1] < df.CLOSE.iloc[-1],\n#         df.CLOSE.iloc[-1] > df.CLOSE.iloc[-2] > df.CLOSE.iloc[-3],\n#     ]): # 3 green candles on SMA\n\n#         print(f\"{df.SYMBOL.iloc[-1]}: 3 green candles on SMA 20 on {df.DATE.iloc[-1]}\")\n\n\n# Get list of all csv files in raw_data_dir\n# csv_files = [f for f in os.listdir(processed_data_dir) if f.endswith('.csv')]\n\n# for file in csv_files:\n#     file_path = base_path / processed_data_dir / f\"{symbol}.csv\"\n#     if os.path.exists(file_path):\n#         df = pd.read_csv(file_path, parse_dates=[\"DATE\"])\n\n#         # Convert daily data to monthly data\n#         # df_monthly = df.resample('M', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n\n#         # Convert daily data to weekly data\n#         df_weekly = df.resample('W', on='DATE').agg({'OPEN': 'first', 'HIGH': 'max', 'LOW': 'min', 'CLOSE': 'last','SYMBOL': 'first'})\n#         df_weekly['SMA_20_C'] = df_weekly.CLOSE.rolling(20).mean()\n#         if \"DATE\" not in df_weekly.columns:\n#             df_weekly[\"DATE\"] = df_weekly.index\n\n#         check_3_green_on_SMA(df_weekly, sma_period=20)\n\n\n# Download csv from URL\n# url = r\"https://www.nseindia.com/api/equity-stockIndices?csv=true&index=SECURITIES%20IN%20F%26O\"\n# df = pd.read_csv(url)\n# df\n\n\n# import requests\n# # Download csv from URL using requests\n# url = r\"https://www.nseindia.com/api/equity-stockIndices?csv=true&index=SECURITIES%20IN%20F%26O\"\n# requests.get(url).content\n\n\n# https://www.nseindia.com/market-data/live-equity-market\n\n# https://www.nseindia.com/api/equity-stockIndices?csv=true&index=NIFTY%20SMALLCAP%2050\n\n\n# init_cap = 200000\n# win_rate = 0.6\n# one_trade_perc = 0.02\n\n# for i in range(200):\n#     if random.random() < win_rate:\n#         init_cap = init_cap * (1 + one_trade_perc)\n#     else:\n#         init_cap = init_cap * (1 - one_trade_perc)\n\n# print(f'{init_cap:,}')\n\n\n# import random\n# random.random()"
  },
  {
    "objectID": "technicals.html",
    "href": "technicals.html",
    "title": "technicals",
    "section": "",
    "text": "Get all raw bhavcopy data\n\nsource\n\n\n\n get_raw_bhavcopy_data ()\n\nPreprocess bhavcopy data\n\nsource\n\n\n\n\n preprocess (df)"
  },
  {
    "objectID": "technicals.html#technical-analysis-utils",
    "href": "technicals.html#technical-analysis-utils",
    "title": "technicals",
    "section": "Technical analysis utils",
    "text": "Technical analysis utils\nGenerate SMA\n\nsource\n\nget_sma\n\n get_sma (df_symbol, period=20, metric='CLOSE')\n\nGenerate Bollinger bands\n\nsource\n\n\nget_bollinger_bands\n\n get_bollinger_bands (df_symbol, period=20, std=2)\n\nGet Donchian channels\n\nsource\n\n\nget_donchian\n\n get_donchian (df_symbol, upper=22, lower=66)\n\nGet Supertrend indicator\n\nsource\n\n\nget_supertrend\n\n get_supertrend (df_symbol, period=12, multiplier=3)\n\nGet candlestick properties data\n\nsource\n\n\nadd_candle_stats\n\n add_candle_stats (df_symbol)\n\nAdd all technical indicator data\n\nsource\n\n\nadd_all_technicals\n\n add_all_technicals (df_symbol)"
  },
  {
    "objectID": "technicals.html#process-all-symbols-and-add-technicals",
    "href": "technicals.html#process-all-symbols-and-add-technicals",
    "title": "technicals",
    "section": "Process all symbols and add technicals",
    "text": "Process all symbols and add technicals\n\nsource\n\nprocess_all_symbols\n\n process_all_symbols ()"
  }
]